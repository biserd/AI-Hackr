Yep — that’s exactly the right fix. A modern “BuiltWith for AI SaaS” scanner needs a rendered DOM + network capture, not just fetch().

Here’s a solid MVP approach: hybrid scan
	•	Passive HTTP scan (cheap, fast, catches headers/cookies/static markers)
	•	Browser render scan (Playwright) (executes JS, catches dynamic tags + runtime network calls)
	•	Optional interaction probe (click “AI/chat” UI and capture the real AI provider signals)

Below is the logic + a drop-in TypeScript Playwright collector you can plug into your existing signature matching.

⸻

Recommended browser-scan logic

1) Render page and collect JS-executed signals

Use Playwright to:
	•	goto(url, waitUntil: 'domcontentloaded')
	•	wait a bit for client apps to hydrate (networkidle is often too strict)
	•	collect:
	•	rendered HTML (page.content())
	•	document scripts (final <script src> list)
	•	meta tags
	•	window hints (e.g., __NEXT_DATA__, __NUXT__, Shopify, etc.)
	•	response headers from main document
	•	cookies (optional)

2) Capture network traffic (this is where AI signals show up)

Listen to requests/responses and store:
	•	domains
	•	paths
	•	methods
	•	status
	•	response content-type
	•	websocket connections

3) Performance controls (critical)

To keep costs down:
	•	block images/fonts/media
	•	cap runtime (e.g., 12–20 seconds)
	•	cap stored network entries (e.g., 300)
	•	cap HTML size (e.g., 2MB)

⸻

TypeScript: Playwright “render + network capture” collector

import { chromium, type Browser, type Page } from "playwright";

export type BrowserSignals = {
  finalUrl: string;
  mainResponse: {
    status: number | null;
    headers: Record<string, string>;
  };
  html: string;
  scriptSrcs: string[];
  meta: Record<string, string[]>;
  cookies: { name: string; value: string; domain?: string; path?: string }[];
  windowHints: Record<string, boolean>;
  network: {
    requests: Array<{
      url: string;
      method: string;
      resourceType: string;
    }>;
    responses: Array<{
      url: string;
      status: number;
      contentType: string | null;
    }>;
    websockets: string[];
    domains: string[];
    paths: string[];
  };
};

type Options = {
  timeoutMs?: number;
  maxHtmlChars?: number;
  maxNetworkEntries?: number;
  blockResources?: boolean;
};

const DEFAULTS: Required<Options> = {
  timeoutMs: 15000,
  maxHtmlChars: 2_000_000,
  maxNetworkEntries: 400,
  blockResources: true,
};

function safeLower(s: string | undefined | null) {
  return (s ?? "").toLowerCase();
}

function getDomain(u: string) {
  try { return new URL(u).hostname; } catch { return ""; }
}

function getPath(u: string) {
  try { return new URL(u).pathname; } catch { return ""; }
}

export async function browserScan(url: string, opts: Options = {}): Promise<BrowserSignals> {
  const o = { ...DEFAULTS, ...opts };

  let browser: Browser | null = null;
  try {
    browser = await chromium.launch({ headless: true });

    const context = await browser.newContext({
      userAgent:
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 " +
        "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
      viewport: { width: 1280, height: 800 },
    });

    const page = await context.newPage();

    // Reduce cost + speed up by blocking heavy resources
    if (o.blockResources) {
      await page.route("**/*", (route) => {
        const rt = route.request().resourceType();
        if (rt === "image" || rt === "font" || rt === "media") return route.abort();
        return route.continue();
      });
    }

    // Network capture
    const reqs: BrowserSignals["network"]["requests"] = [];
    const resps: BrowserSignals["network"]["responses"] = [];
    const ws: string[] = [];

    page.on("request", (req) => {
      if (reqs.length >= o.maxNetworkEntries) return;
      reqs.push({
        url: req.url(),
        method: req.method(),
        resourceType: req.resourceType(),
      });
    });

    page.on("response", async (resp) => {
      if (resps.length >= o.maxNetworkEntries) return;
      const headers = resp.headers();
      resps.push({
        url: resp.url(),
        status: resp.status(),
        contentType: headers["content-type"] ?? null,
      });
    });

    page.on("websocket", (socket) => {
      ws.push(socket.url());
    });

    // Navigate
    const mainResp = await page.goto(url, {
      waitUntil: "domcontentloaded",
      timeout: o.timeoutMs,
    });

    // Give SPA apps a moment to hydrate
    await page.waitForTimeout(1200);

    // Collect rendered DOM
    let html = await page.content();
    if (html.length > o.maxHtmlChars) html = html.slice(0, o.maxHtmlChars);

    // Script srcs present after JS render
    const scriptSrcs = await page.$$eval("script[src]", (els) =>
      els.map((e) => (e as HTMLScriptElement).src).filter(Boolean)
    );

    // Meta tags
    const meta = await page.$$eval("meta", (els) => {
      const out: Record<string, string[]> = {};
      for (const el of els) {
        const name = el.getAttribute("name") || el.getAttribute("property") || el.getAttribute("http-equiv");
        const content = el.getAttribute("content");
        if (!name || !content) continue;
        (out[name] ||= []).push(content);
      }
      return out;
    });

    // Useful runtime hints (extend as needed)
    const windowHints = await page.evaluate(() => {
      const w = window as any;
      return {
        __NEXT_DATA__: Boolean(w.__NEXT_DATA__),
        __NUXT__: Boolean(w.__NUXT__),
        Shopify: Boolean(w.Shopify),
      };
    });

    // Cookies
    const cookies = (await context.cookies()).map((c) => ({
      name: c.name,
      value: c.value,
      domain: c.domain,
      path: c.path,
    }));

    const mainHeaders = (mainResp ? mainResp.headers() : {}) as Record<string, string>;

    const domains = Array.from(
      new Set([
        ...reqs.map((r) => getDomain(r.url)).filter(Boolean),
        ...resps.map((r) => getDomain(r.url)).filter(Boolean),
      ])
    );

    const paths = Array.from(
      new Set([
        ...reqs.map((r) => getPath(r.url)).filter(Boolean),
        ...resps.map((r) => getPath(r.url)).filter(Boolean),
      ])
    );

    return {
      finalUrl: page.url(),
      mainResponse: {
        status: mainResp ? mainResp.status() : null,
        headers: Object.fromEntries(Object.entries(mainHeaders).map(([k, v]) => [safeLower(k), v])),
      },
      html,
      scriptSrcs,
      meta,
      cookies,
      windowHints,
      network: {
        requests: reqs,
        responses: resps,
        websockets: ws,
        domains,
        paths,
      },
    };
  } finally {
    await browser?.close().catch(() => {});
  }
}


⸻

How to feed this into your detection engine

From BrowserSignals, map to your evidence types:
	•	header: signals.mainResponse.headers
	•	cookie: signals.cookies[].name
	•	html: signals.html
	•	script_src: signals.scriptSrcs[]
	•	meta: signals.meta
	•	network_domain: signals.network.domains[]
	•	network_path: signals.network.paths[]
	•	script_body: (optional) you can also fetch the top N scripts from scriptSrcs and search for SDK strings

AI provider detection becomes far better because in probe mode you’ll often see:
	•	generativelanguage.googleapis.com (Gemini API)
	•	api.openai.com / *.openai.azure.com
	•	api.anthropic.com
…or at least OpenAI-compatible paths (/v1/chat/completions) even if proxied.

⸻

MVP “probe interaction” add-on (optional but powerful)

Once the render scan runs, do a lightweight interaction pass:
	•	Find candidate buttons by text: ai|assistant|chat|ask
	•	Click, type “Hello”, submit
	•	Capture new network entries after the click

This is how you upgrade detection rate from “sometimes” to “often”.

⸻

If you want, paste your current scanner function (or how you store signals today) and I’ll show the exact integration: merge(passiveSignals, browserSignals) + run your signature DB scoring on the combined evidence.